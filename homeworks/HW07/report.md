# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9) *(включая `sample_id`; признаков для кластеризации: 8)*
- Признаки: только числовые (`f01..f08`)
- Пропуски: нет
- "Подлости" датасета: разные шкалы признаков + присутствуют шумовые/слабоинформативные признаки → без масштабирования distance-based методы работают некорректно.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4) *(включая `sample_id`; признаков: 3)*
- Признаки: только числовые (`x1`, `x2`, `z_noise`)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура + выбросы/шум + лишний шумовой признак `z_noise` (имеет заметную дисперсию и может ухудшать расстояния).

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000, 33) *(включая `sample_id`; признаков: 32)*
- Признаки: 30 числовых (`n01..n30`) + 2 категориальных (`cat_a`, `cat_b`)
- Пропуски: есть в числовых признаках (~1.7–2.2% по колонкам, в зависимости от признака)
- "Подлости" датасета: высокая размерность + категориальные признаки + пропуски → нужен аккуратный препроцессинг (imputation + scaling + encoding).

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг:
  - `sample_id` исключался из признаков и использовался только как идентификатор для сохранения результатов.
  - Для числовых признаков: `SimpleImputer(strategy="median")` + `StandardScaler()`.
  - Для категориальных (только dataset-04): `SimpleImputer(strategy="most_frequent")` + `OneHotEncoder(handle_unknown="ignore")`.
  - PCA использовался **только для визуализации** (2D), не для обучения моделей.
- Поиск гиперпараметров:
  - KMeans: перебор `k` в диапазоне **2…20**, фиксированы `random_state=42`, `n_init=20`. Строился график `silhouette vs k`.
  - AgglomerativeClustering: перебор `k` в диапазоне **2…20**, сравнение `linkage ∈ {ward, average}`.
  - DBSCAN: перебор `min_samples ∈ {5, 10}`; кандидаты `eps` выбирались эвристически по k-distance (расстояние до k-го соседа) через набор квантилей **[0.90, 0.93, 0.95, 0.97, 0.98, 0.99]** распределения k-distance.
  - Выбор “лучшего”: по умолчанию использовался критерий **максимум silhouette** (для DBSCAN — на non-noise точках). Дополнительно контролировались DB (ниже лучше) и CH (выше лучше), а для DBSCAN — доля шума.
- Метрики: `silhouette_score` (↑ лучше), `davies_bouldin_score` (↓ лучше), `calinski_harabasz_score` (↑ лучше).
  - Для DBSCAN дополнительно считалась доля шума (`label=-1`).
  - Метрики для DBSCAN считались **на подмножестве без шума** (`label != -1`) и это явно фиксировалось в выводах.
- Визуализация:
  - Для каждого датасета строился PCA(2D) scatter по меткам лучшей модели.
  - Дополнительно строились графики подбора параметров (например, `silhouette vs k`, `k-distance plot`, `silhouette vs eps`).
  - t-SNE не использовался.

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

На каждом из 3 датасетов сравнивались:

- **KMeans**
  - Подбор: `k ∈ [2..20]`
  - Фиксировали: `random_state=42`, `n_init=20`
- **AgglomerativeClustering**
  - Подбор: `k ∈ [2..20]`, `linkage ∈ {ward, average}`
- **DBSCAN** (дополнительно как 3-й метод)
  - Подбор: `min_samples ∈ {5, 10}`, `eps` из сетки по квантилям k-distance
  - Дополнительно: оценивалась доля шума, метрики считались на non-noise

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: **KMeans**, `k=2`, `random_state=42`, `n_init=20`
- Метрики (silhouette / DB / CH):
  - silhouette = **0.5216**
  - Davies-Bouldin = **0.6853**
  - Calinski-Harabasz = **11786.95**
- Если был DBSCAN: доля шума и комментарий
  - Лучший DBSCAN (по silhouette на non-noise) дал silhouette ≈ **0.3954**, доля шума ≈ **0.08**
  - Это хуже, чем KMeans, что говорит о более “геометрически простых” (почти шаровых) кластерах после масштабирования.
- Коротко: почему это решение выглядит разумным именно для этого датасета  
  Датасет без пропусков и категориальных, но с сильно разными шкалами — после `StandardScaler` KMeans/иерархическая кластеризация показывают согласованно хорошее разделение. DBSCAN выделяет заметную долю “шума”, но по внутренним метрикам качество ниже, поэтому KMeans(k=2) выглядит наиболее уместным.

### 4.2 Dataset B

- Лучший метод и параметры: **AgglomerativeClustering**, `linkage="average"`, `k=2`
- Метрики (silhouette / DB / CH):
  - silhouette = **0.4198**
  - Davies-Bouldin = **0.8791**
  - Calinski-Harabasz = **395.48**
- Если был DBSCAN: доля шума и комментарий
  - Лучший DBSCAN (на non-noise) дал silhouette ≈ **0.3726**, доля шума ≈ **0.0326**
  - DBSCAN требует аккуратного подбора `eps/min_samples`; качество ниже, чем у Agglomerative(average).
- Коротко: почему это решение выглядит разумным именно для этого датасета  
  На этом датасете KMeans даёт более слабый silhouette (~0.307), что согласуется с нелинейной структурой/выбросами и наличием шумового признака. Average-linkage оказался лучше по silhouette и не требует подбора `eps` как DBSCAN, поэтому выбран как итоговый метод.

### 4.3 Dataset C

- Лучший метод и параметры: **DBSCAN**, `eps≈3.09165`, `min_samples=10`
- Метрики (silhouette / DB / CH):
  - noise_frac = **0.0046**
  - silhouette (на non-noise) = **0.4484**
  - Davies-Bouldin (на non-noise) = **0.9740**
  - Calinski-Harabasz (на non-noise) = **5094.69**
- Если был DBSCAN: доля шума и комментарий
  - Доля шума очень маленькая (~0.46%), т.е. DBSCAN в основном кластеризует почти все точки и отделяет небольшое количество выбросов/пограничных наблюдений.
- Коротко: почему это решение выглядит разумным именно для этого датасета  
  Датасет высокоразмерный, с пропусками и категориальными признаками, поэтому критичен корректный препроцессинг (imputation + scaling + OHE). DBSCAN показал лучшую silhouette и при этом естественно выделил небольшой шум, что удобно в присутствии выбросов/редких объектов. KMeans/Agglo дают очень близкую silhouette (~0.447 при k=5), но требуют заранее задавать k и не выделяют шум.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?  
  KMeans чувствителен к (1) масштабам признаков, (2) выбросам, (3) нелинейным формам кластеров. На dataset-01 без `StandardScaler` результат был бы доминирован признаками с крупными шкалами. На dataset-02 KMeans даёт более слабую метрику, что согласуется с более сложной структурой.
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?  
  Agglomerative с `average` смог лучше отработать dataset-02 (по silhouette), т.к. менее жёстко предполагает сферическую форму кластеров. DBSCAN оказался полезен на dataset-04: выделил небольшой шум и дал лучшую silhouette без необходимости задавать число кластеров.
- Что сильнее всего влияло на результат?  
  Масштабирование (dataset-01) и шумовой/неинформативный признак (dataset-02) заметно влияли на расстояния. Для dataset-04 критичны пропуски и категориальные признаки: без иммутации и one-hot кодирования корректная кластеризация невозможна.

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход)  
  Для одного датасета выполнялись 5 запусков KMeans с разными `random_state` (seeds: 0..4) при фиксированном `k`, далее считалась попарная похожесть разбиений через **ARI**.
- Что получилось (в 3-6 строк)  
  ARI-матрица и heatmap сохранены в `artifacts/figures/*_kmeans_stability_ari.png`.  
  *(Вставьте сюда число из `best_configs.json`: `ari_mean_offdiag`.)*  
  Средний ARI вне диагонали: **<ARI_MEAN_OFFDIAG>**.
- Вывод: устойчиво/неустойчиво и почему вы так считаете  
  Если средний ARI близок к 1, то разбиение устойчиво к смене seed (локальные минимумы почти не влияют). Если ARI заметно ниже, то результат KMeans зависит от инициализации и стоит либо увеличить `n_init`, либо менять модель/признаковое пространство.

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - профили признаков (средние/медианы) **или**
  - любая другая логичная интерпретация

Интерпретация выполнялась через (а) визуализацию PCA(2D) и (б) сравнение профилей признаков по кластерам: средние/медианы числовых признаков (в стандартизованном виде) и распределение категориальных значений (для dataset-04). Это позволяет понять, какие признаки сильнее всего отличают кластеры, даже без истинных меток.

## 6. Conclusion

- Внутренние метрики (silhouette/DB/CH) полезны для сравнения разбиений без разметки, но их нужно интерпретировать совместно и с учётом структуры данных.
- Масштабирование критично для distance-based кластеризации: без `StandardScaler` результаты могут “ехать” из-за разных шкал.
- KMeans хорошо работает при близких к “шару” кластерах и отсутствии сильных выбросов; требует выбора `k`.
- AgglomerativeClustering чувствителен к выбору `linkage`; average-linkage может быть удачнее при более сложной форме кластеров.
- DBSCAN удобен, когда есть выбросы/шум и хочется не задавать `k`, но он чувствителен к `eps` и `min_samples`.
- Для DBSCAN важно отдельно учитывать шум (`label=-1`) и честно описывать, как считались метрики (на non-noise).
- В высокоразмерных данных с пропусками и категориальными признаками корректный препроцессинг (imputation + encoding + scaling) — обязательное условие осмысленного результата.